{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def top_patients(NUM_patients=1,MODEL='feature_matrix_model2_stage1.csv'):\n",
    "    df = pd.read_csv(MODEL).sort_values(['max_malig'],ascending=[False])\n",
    "    top_patients_dict = {}\n",
    "    for i in range(NUM_patients):\n",
    "        \n",
    "        patient = df.iloc[i]['Unnamed: 0'][:-4]\n",
    "        top_patients_dict[patient] = {}\n",
    "        \n",
    "        malignancy = df.iloc[i]['max_malig']\n",
    "        top_patients_dict[patient]['max_malig'] = malignancy\n",
    "        \n",
    "        print ('Patient',i+1,':\\t',patient,'\\nMalignancy',i+1,':\\t',malignancy)\n",
    "        \n",
    "        with open('./LUNA_model_v2/dict_'+patient+'.pickle', 'wb') as handle:\n",
    "            pickle.dump(top_patients_dict,handle,protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        print ('\\tDictionary SAVED for..',patient)\n",
    "        \n",
    "    return top_patients_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient 1 :\t 07bca4290a2530091ce1d5f200d9d526 \n",
      "Malignancy 1 :\t 0.534115552902\n",
      "\tDictionary SAVED for.. 07bca4290a2530091ce1d5f200d9d526\n",
      "Patient 2 :\t 5a42f0a0d1e060531c20d04ed23efc02 \n",
      "Malignancy 2 :\t 0.53409910202\n",
      "\tDictionary SAVED for.. 5a42f0a0d1e060531c20d04ed23efc02\n"
     ]
    }
   ],
   "source": [
    "\n",
    "top_patients_dict = top_patients()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from keras.models import load_model\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.15\n",
    "set_session(tf.Session(config=config))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def top_patients_predict(top_patients_DICT,MODEL,TOP=1):\n",
    "    top_patients_dict = deepcopy(top_patients_DICT)\n",
    "    for patient in top_patients_dict.keys():\n",
    "        print ('Patient..',patient)\n",
    "        patient_load = np.load('../data/stage1_voxels_mask/'+patient+'.npz')\n",
    "        voxels = patient_load['vox']\n",
    "        print ('\\tNumber of voxels to predict..',voxels.shape[0])\n",
    "        \n",
    "        preds = np.array(MODEL.predict(x=voxels,batch_size=5))\n",
    "        top_patients_dict[patient]['preds'] = preds\n",
    "        np.save('./LUNA_model_v2/preds_'+patient+'.npy',preds)\n",
    "        print ('\\tVoxels predicted..',len(preds))\n",
    "        \n",
    "        top_ixs = np.argsort(preds[0],axis=0)[-TOP:]\n",
    "        top_ixs = [i[0] for i in top_ixs]\n",
    "        top_patients_dict[patient]['top_ixs'] = top_ixs\n",
    "        print ('\\tNumber of top voxels for visualization..',len(top_ixs))\n",
    "        \n",
    "        top_patients_dict[patient]['top_voxels'] = np.vstack([voxels[i] for i in top_ixs])\n",
    "        with open('./LUNA_model_v2/dict_top_patients_predict.pickle', 'wb') as handle:\n",
    "            pickle.dump(top_patients_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        print ('\\tDictionary SAVED for..',patient)\n",
    "        \n",
    "    return top_patients_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python3.5/site-packages/keras/engine/topology.py:1206: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  return cls(**config)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient.. 07bca4290a2530091ce1d5f200d9d526\n",
      "\tNumber of voxels to predict.. 472\n",
      "\tVoxels predicted.. 4\n",
      "\tNumber of top voxels for visualization.. 1\n",
      "\tDictionary SAVED for.. 07bca4290a2530091ce1d5f200d9d526\n"
     ]
    }
   ],
   "source": [
    "\n",
    "LUNA_model_v2 = load_model('../LungCancer/Models/LUNA_model_v2.h5')\n",
    "top_patients_dict = top_patients_predict(top_patients_dict,LUNA_model_v2,TOP=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def top_voxels_predict(top_patients_DICT,MODEL):\n",
    "    top_patients_dict = deepcopy(top_patients_DICT)\n",
    "    for patient in top_patients_dict.keys():\n",
    "        print ('Patient..',patient)\n",
    "        \n",
    "        top_voxels = top_patients_dict[patient]['top_voxels']\n",
    "        \n",
    "        for i in range(top_voxels.shape[0]):\n",
    "            print ('\\tPredicting voxel',i+1)\n",
    "            start = time.time()\n",
    "            \n",
    "            voxel = np.squeeze(top_voxels[i])\n",
    "            count = 0\n",
    "            preds_top_voxels = []\n",
    "            \n",
    "            for e in np.nditer(voxel,op_flags=['readwrite']):\n",
    "                e_original = e.copy()\n",
    "                e[...] = 0\n",
    "                preds = MODEL.predict(x=np.expand_dims(np.expand_dims(voxel,axis=0),axis=0),batch_size=1)\n",
    "                preds = [p[0][0] for p in preds]\n",
    "                preds_top_voxels.append(preds)\n",
    "                e[...] = e_original\n",
    "                count +=1\n",
    "                if count%1000==0:\n",
    "                    print ('\\t\\tOut of',64*64*64,',',count,'are done in',time.time()-start)\n",
    "                    start = time.time()\n",
    "            top_patients_dict[patient][i+1] = preds_top_voxels\n",
    "        \n",
    "        with open('./LUNA_model_v2/dict_top_voxels_predict.pickle', 'wb') as handle:\n",
    "            pickle.dump(top_patients_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        print ('\\tDictionary SAVED for..',patient)\n",
    "        \n",
    "    return top_patients_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient.. 07bca4290a2530091ce1d5f200d9d526\n",
      "\tPredicting voxel 1\n",
      "\t\tOut of 262144 , 1000 are done in 13.391921043395996\n",
      "\t\tOut of 262144 , 2000 are done in 12.25285530090332\n",
      "\t\tOut of 262144 , 3000 are done in 13.332795143127441\n",
      "\t\tOut of 262144 , 4000 are done in 13.787899017333984\n",
      "\t\tOut of 262144 , 5000 are done in 13.63324761390686\n",
      "\t\tOut of 262144 , 6000 are done in 13.795911312103271\n",
      "\t\tOut of 262144 , 7000 are done in 13.718749046325684\n",
      "\t\tOut of 262144 , 8000 are done in 14.14165472984314\n",
      "\t\tOut of 262144 , 9000 are done in 12.427061557769775\n",
      "\t\tOut of 262144 , 10000 are done in 13.88233494758606\n",
      "\t\tOut of 262144 , 11000 are done in 13.47255563735962\n",
      "\t\tOut of 262144 , 12000 are done in 13.882982015609741\n",
      "\t\tOut of 262144 , 13000 are done in 13.407175302505493\n",
      "\t\tOut of 262144 , 14000 are done in 13.370752573013306\n",
      "\t\tOut of 262144 , 15000 are done in 13.732171058654785\n",
      "\t\tOut of 262144 , 16000 are done in 11.773198127746582\n",
      "\t\tOut of 262144 , 17000 are done in 10.873040199279785\n",
      "\t\tOut of 262144 , 18000 are done in 12.597906351089478\n",
      "\t\tOut of 262144 , 19000 are done in 13.640632390975952\n",
      "\t\tOut of 262144 , 20000 are done in 14.186645269393921\n",
      "\t\tOut of 262144 , 21000 are done in 13.690017700195312\n",
      "\t\tOut of 262144 , 22000 are done in 14.14747667312622\n",
      "\t\tOut of 262144 , 23000 are done in 13.885721445083618\n",
      "\t\tOut of 262144 , 24000 are done in 13.724558353424072\n",
      "\t\tOut of 262144 , 25000 are done in 13.098390102386475\n",
      "\t\tOut of 262144 , 26000 are done in 13.999734878540039\n",
      "\t\tOut of 262144 , 27000 are done in 13.986807107925415\n",
      "\t\tOut of 262144 , 28000 are done in 13.883296489715576\n",
      "\t\tOut of 262144 , 29000 are done in 14.335330963134766\n",
      "\t\tOut of 262144 , 30000 are done in 13.977370023727417\n",
      "\t\tOut of 262144 , 31000 are done in 13.684156656265259\n",
      "\t\tOut of 262144 , 32000 are done in 13.112621068954468\n",
      "\t\tOut of 262144 , 33000 are done in 14.156111478805542\n",
      "\t\tOut of 262144 , 34000 are done in 13.917662620544434\n",
      "\t\tOut of 262144 , 35000 are done in 13.840465068817139\n",
      "\t\tOut of 262144 , 36000 are done in 14.133490800857544\n",
      "\t\tOut of 262144 , 37000 are done in 13.81228232383728\n",
      "\t\tOut of 262144 , 38000 are done in 13.521478652954102\n",
      "\t\tOut of 262144 , 39000 are done in 13.671857833862305\n",
      "\t\tOut of 262144 , 40000 are done in 13.961702585220337\n",
      "\t\tOut of 262144 , 41000 are done in 13.740578174591064\n",
      "\t\tOut of 262144 , 42000 are done in 14.196654081344604\n",
      "\t\tOut of 262144 , 43000 are done in 13.57021188735962\n",
      "\t\tOut of 262144 , 44000 are done in 14.255325317382812\n",
      "\t\tOut of 262144 , 45000 are done in 13.018256902694702\n",
      "\t\tOut of 262144 , 46000 are done in 13.62744688987732\n",
      "\t\tOut of 262144 , 47000 are done in 14.083948373794556\n",
      "\t\tOut of 262144 , 48000 are done in 13.984357118606567\n",
      "\t\tOut of 262144 , 49000 are done in 13.963937520980835\n",
      "\t\tOut of 262144 , 50000 are done in 13.484646558761597\n",
      "\t\tOut of 262144 , 51000 are done in 14.12313985824585\n",
      "\t\tOut of 262144 , 52000 are done in 12.476370334625244\n",
      "\t\tOut of 262144 , 53000 are done in 11.250577211380005\n",
      "\t\tOut of 262144 , 54000 are done in 12.411901950836182\n",
      "\t\tOut of 262144 , 55000 are done in 14.253512859344482\n",
      "\t\tOut of 262144 , 56000 are done in 13.841860294342041\n",
      "\t\tOut of 262144 , 57000 are done in 14.048095464706421\n",
      "\t\tOut of 262144 , 58000 are done in 14.285765886306763\n",
      "\t\tOut of 262144 , 59000 are done in 13.763567686080933\n",
      "\t\tOut of 262144 , 60000 are done in 13.919355869293213\n",
      "\t\tOut of 262144 , 61000 are done in 12.350737571716309\n",
      "\t\tOut of 262144 , 62000 are done in 13.77060842514038\n",
      "\t\tOut of 262144 , 63000 are done in 13.787662029266357\n",
      "\t\tOut of 262144 , 64000 are done in 14.081711292266846\n",
      "\t\tOut of 262144 , 65000 are done in 13.951437950134277\n",
      "\t\tOut of 262144 , 66000 are done in 14.212465286254883\n",
      "\t\tOut of 262144 , 67000 are done in 14.026033878326416\n",
      "\t\tOut of 262144 , 68000 are done in 13.260700941085815\n",
      "\t\tOut of 262144 , 69000 are done in 13.67299509048462\n",
      "\t\tOut of 262144 , 70000 are done in 14.204121589660645\n",
      "\t\tOut of 262144 , 71000 are done in 14.08427095413208\n",
      "\t\tOut of 262144 , 72000 are done in 14.03780484199524\n",
      "\t\tOut of 262144 , 73000 are done in 14.253139972686768\n",
      "\t\tOut of 262144 , 74000 are done in 13.61974811553955\n",
      "\t\tOut of 262144 , 75000 are done in 13.094918727874756\n",
      "\t\tOut of 262144 , 76000 are done in 14.042730808258057\n",
      "\t\tOut of 262144 , 77000 are done in 13.743642568588257\n",
      "\t\tOut of 262144 , 78000 are done in 13.85947322845459\n",
      "\t\tOut of 262144 , 79000 are done in 14.047340631484985\n",
      "\t\tOut of 262144 , 80000 are done in 13.721659183502197\n",
      "\t\tOut of 262144 , 81000 are done in 13.601896286010742\n",
      "\t\tOut of 262144 , 82000 are done in 13.069558382034302\n",
      "\t\tOut of 262144 , 83000 are done in 13.934370517730713\n",
      "\t\tOut of 262144 , 84000 are done in 13.90575098991394\n",
      "\t\tOut of 262144 , 85000 are done in 14.1809401512146\n",
      "\t\tOut of 262144 , 86000 are done in 14.058839559555054\n",
      "\t\tOut of 262144 , 87000 are done in 13.963427066802979\n",
      "\t\tOut of 262144 , 88000 are done in 13.685129880905151\n",
      "\t\tOut of 262144 , 89000 are done in 11.168155908584595\n",
      "\t\tOut of 262144 , 90000 are done in 10.92104721069336\n",
      "\t\tOut of 262144 , 91000 are done in 11.188786268234253\n",
      "\t\tOut of 262144 , 92000 are done in 10.80278468132019\n",
      "\t\tOut of 262144 , 93000 are done in 11.158903360366821\n",
      "\t\tOut of 262144 , 94000 are done in 10.812952756881714\n",
      "\t\tOut of 262144 , 95000 are done in 11.129044771194458\n",
      "\t\tOut of 262144 , 96000 are done in 10.99673318862915\n",
      "\t\tOut of 262144 , 97000 are done in 10.988635778427124\n",
      "\t\tOut of 262144 , 98000 are done in 11.145333766937256\n",
      "\t\tOut of 262144 , 99000 are done in 10.739603757858276\n",
      "\t\tOut of 262144 , 100000 are done in 11.096142292022705\n",
      "\t\tOut of 262144 , 101000 are done in 10.823240518569946\n",
      "\t\tOut of 262144 , 102000 are done in 11.090677261352539\n",
      "\t\tOut of 262144 , 103000 are done in 10.839234352111816\n",
      "\t\tOut of 262144 , 104000 are done in 12.969033002853394\n",
      "\t\tOut of 262144 , 105000 are done in 13.490078210830688\n",
      "\t\tOut of 262144 , 106000 are done in 13.57440972328186\n",
      "\t\tOut of 262144 , 107000 are done in 13.571183681488037\n",
      "\t\tOut of 262144 , 108000 are done in 13.893270254135132\n",
      "\t\tOut of 262144 , 109000 are done in 14.00116515159607\n",
      "\t\tOut of 262144 , 110000 are done in 13.751560688018799\n",
      "\t\tOut of 262144 , 111000 are done in 12.929630041122437\n",
      "\t\tOut of 262144 , 112000 are done in 13.97036600112915\n",
      "\t\tOut of 262144 , 113000 are done in 13.873143672943115\n",
      "\t\tOut of 262144 , 114000 are done in 13.634123086929321\n",
      "\t\tOut of 262144 , 115000 are done in 13.474851608276367\n",
      "\t\tOut of 262144 , 116000 are done in 13.626678705215454\n",
      "\t\tOut of 262144 , 117000 are done in 13.59846830368042\n",
      "\t\tOut of 262144 , 118000 are done in 12.7676100730896\n",
      "\t\tOut of 262144 , 119000 are done in 13.459015130996704\n",
      "\t\tOut of 262144 , 120000 are done in 14.144362211227417\n",
      "\t\tOut of 262144 , 121000 are done in 13.81976580619812\n",
      "\t\tOut of 262144 , 122000 are done in 13.914437294006348\n",
      "\t\tOut of 262144 , 123000 are done in 14.179751634597778\n",
      "\t\tOut of 262144 , 124000 are done in 13.651132345199585\n",
      "\t\tOut of 262144 , 125000 are done in 12.838980436325073\n",
      "\t\tOut of 262144 , 126000 are done in 13.391227722167969\n",
      "\t\tOut of 262144 , 127000 are done in 13.778382301330566\n",
      "\t\tOut of 262144 , 128000 are done in 13.838797569274902\n",
      "\t\tOut of 262144 , 129000 are done in 13.877497673034668\n",
      "\t\tOut of 262144 , 130000 are done in 13.92203140258789\n",
      "\t\tOut of 262144 , 131000 are done in 13.55974268913269\n",
      "\t\tOut of 262144 , 132000 are done in 12.87963080406189\n",
      "\t\tOut of 262144 , 133000 are done in 13.68485164642334\n",
      "\t\tOut of 262144 , 134000 are done in 13.69084644317627\n",
      "\t\tOut of 262144 , 135000 are done in 13.682347774505615\n",
      "\t\tOut of 262144 , 136000 are done in 13.81705927848816\n",
      "\t\tOut of 262144 , 137000 are done in 13.741925477981567\n",
      "\t\tOut of 262144 , 138000 are done in 14.132359981536865\n",
      "\t\tOut of 262144 , 139000 are done in 11.489524364471436\n",
      "\t\tOut of 262144 , 140000 are done in 10.911836624145508\n",
      "\t\tOut of 262144 , 141000 are done in 11.21359658241272\n",
      "\t\tOut of 262144 , 142000 are done in 11.520442962646484\n",
      "\t\tOut of 262144 , 143000 are done in 13.673407554626465\n",
      "\t\tOut of 262144 , 144000 are done in 13.896698236465454\n",
      "\t\tOut of 262144 , 145000 are done in 13.552631855010986\n",
      "\t\tOut of 262144 , 146000 are done in 13.949202060699463\n",
      "\t\tOut of 262144 , 147000 are done in 13.911898851394653\n",
      "\t\tOut of 262144 , 148000 are done in 13.454855918884277\n",
      "\t\tOut of 262144 , 149000 are done in 12.665657997131348\n",
      "\t\tOut of 262144 , 150000 are done in 13.350141048431396\n",
      "\t\tOut of 262144 , 151000 are done in 13.501078128814697\n",
      "\t\tOut of 262144 , 152000 are done in 13.290666818618774\n",
      "\t\tOut of 262144 , 153000 are done in 13.46678614616394\n",
      "\t\tOut of 262144 , 154000 are done in 13.23941445350647\n",
      "\t\tOut of 262144 , 155000 are done in 13.867012739181519\n",
      "\t\tOut of 262144 , 156000 are done in 12.168296337127686\n",
      "\t\tOut of 262144 , 157000 are done in 13.637641668319702\n",
      "\t\tOut of 262144 , 158000 are done in 13.148702621459961\n",
      "\t\tOut of 262144 , 159000 are done in 13.639865398406982\n",
      "\t\tOut of 262144 , 160000 are done in 13.733774900436401\n",
      "\t\tOut of 262144 , 161000 are done in 13.387259244918823\n",
      "\t\tOut of 262144 , 162000 are done in 13.578987121582031\n",
      "\t\tOut of 262144 , 163000 are done in 12.444336175918579\n",
      "\t\tOut of 262144 , 164000 are done in 13.572966575622559\n",
      "\t\tOut of 262144 , 165000 are done in 13.33674430847168\n",
      "\t\tOut of 262144 , 166000 are done in 13.668512105941772\n",
      "\t\tOut of 262144 , 167000 are done in 13.282997846603394\n",
      "\t\tOut of 262144 , 168000 are done in 13.813758373260498\n",
      "\t\tOut of 262144 , 169000 are done in 13.040368556976318\n",
      "\t\tOut of 262144 , 170000 are done in 13.067805290222168\n",
      "\t\tOut of 262144 , 171000 are done in 12.832329511642456\n",
      "\t\tOut of 262144 , 172000 are done in 13.761460304260254\n",
      "\t\tOut of 262144 , 173000 are done in 13.276788473129272\n",
      "\t\tOut of 262144 , 174000 are done in 13.645453214645386\n",
      "\t\tOut of 262144 , 175000 are done in 13.57417917251587\n",
      "\t\tOut of 262144 , 176000 are done in 13.26727819442749\n",
      "\t\tOut of 262144 , 177000 are done in 13.443809270858765\n",
      "\t\tOut of 262144 , 178000 are done in 10.773949384689331\n",
      "\t\tOut of 262144 , 179000 are done in 11.164421081542969\n",
      "\t\tOut of 262144 , 180000 are done in 10.80923843383789\n",
      "\t\tOut of 262144 , 181000 are done in 11.094176054000854\n",
      "\t\tOut of 262144 , 182000 are done in 10.689398765563965\n",
      "\t\tOut of 262144 , 183000 are done in 12.696004390716553\n",
      "\t\tOut of 262144 , 184000 are done in 13.306307792663574\n",
      "\t\tOut of 262144 , 185000 are done in 13.562094688415527\n",
      "\t\tOut of 262144 , 186000 are done in 13.359837293624878\n",
      "\t\tOut of 262144 , 187000 are done in 13.459315061569214\n",
      "\t\tOut of 262144 , 188000 are done in 13.127393245697021\n",
      "\t\tOut of 262144 , 189000 are done in 13.621479988098145\n",
      "\t\tOut of 262144 , 190000 are done in 12.114909172058105\n",
      "\t\tOut of 262144 , 191000 are done in 13.510003805160522\n",
      "\t\tOut of 262144 , 192000 are done in 13.188897609710693\n",
      "\t\tOut of 262144 , 193000 are done in 13.533225536346436\n",
      "\t\tOut of 262144 , 194000 are done in 13.200653553009033\n",
      "\t\tOut of 262144 , 195000 are done in 13.630707502365112\n",
      "\t\tOut of 262144 , 196000 are done in 13.563930988311768\n",
      "\t\tOut of 262144 , 197000 are done in 12.207800388336182\n",
      "\t\tOut of 262144 , 198000 are done in 13.277780771255493\n",
      "\t\tOut of 262144 , 199000 are done in 13.379142999649048\n",
      "\t\tOut of 262144 , 200000 are done in 13.555871486663818\n",
      "\t\tOut of 262144 , 201000 are done in 13.431122303009033\n",
      "\t\tOut of 262144 , 202000 are done in 13.237940073013306\n",
      "\t\tOut of 262144 , 203000 are done in 13.067662477493286\n",
      "\t\tOut of 262144 , 204000 are done in 12.283235311508179\n",
      "\t\tOut of 262144 , 205000 are done in 13.227336645126343\n",
      "\t\tOut of 262144 , 206000 are done in 13.673572540283203\n",
      "\t\tOut of 262144 , 207000 are done in 13.420351505279541\n",
      "\t\tOut of 262144 , 208000 are done in 13.354497909545898\n",
      "\t\tOut of 262144 , 209000 are done in 13.255064487457275\n",
      "\t\tOut of 262144 , 210000 are done in 13.479082107543945\n",
      "\t\tOut of 262144 , 211000 are done in 12.670550107955933\n",
      "\t\tOut of 262144 , 212000 are done in 13.071474313735962\n",
      "\t\tOut of 262144 , 213000 are done in 13.2774658203125\n",
      "\t\tOut of 262144 , 214000 are done in 13.666489362716675\n",
      "\t\tOut of 262144 , 215000 are done in 13.655186176300049\n",
      "\t\tOut of 262144 , 216000 are done in 13.341974258422852\n",
      "\t\tOut of 262144 , 217000 are done in 13.689228534698486\n",
      "\t\tOut of 262144 , 218000 are done in 12.91538381576538\n",
      "\t\tOut of 262144 , 219000 are done in 11.019649028778076\n",
      "\t\tOut of 262144 , 220000 are done in 10.79278826713562\n",
      "\t\tOut of 262144 , 221000 are done in 11.034680843353271\n",
      "\t\tOut of 262144 , 222000 are done in 10.723178148269653\n",
      "\t\tOut of 262144 , 223000 are done in 11.011600017547607\n",
      "\t\tOut of 262144 , 224000 are done in 10.663574934005737\n",
      "\t\tOut of 262144 , 225000 are done in 10.946533918380737\n",
      "\t\tOut of 262144 , 226000 are done in 10.522655248641968\n",
      "\t\tOut of 262144 , 227000 are done in 10.889882564544678\n",
      "\t\tOut of 262144 , 228000 are done in 10.586244583129883\n",
      "\t\tOut of 262144 , 229000 are done in 10.902799844741821\n",
      "\t\tOut of 262144 , 230000 are done in 10.642767906188965\n",
      "\t\tOut of 262144 , 231000 are done in 10.960561752319336\n",
      "\t\tOut of 262144 , 232000 are done in 10.639734268188477\n",
      "\t\tOut of 262144 , 233000 are done in 10.976866960525513\n",
      "\t\tOut of 262144 , 234000 are done in 10.629351377487183\n",
      "\t\tOut of 262144 , 235000 are done in 10.989248037338257\n",
      "\t\tOut of 262144 , 236000 are done in 10.6847505569458\n",
      "\t\tOut of 262144 , 237000 are done in 10.882784128189087\n",
      "\t\tOut of 262144 , 238000 are done in 10.630754470825195\n",
      "\t\tOut of 262144 , 239000 are done in 10.963424444198608\n",
      "\t\tOut of 262144 , 240000 are done in 12.244855880737305\n",
      "\t\tOut of 262144 , 241000 are done in 13.194205045700073\n",
      "\t\tOut of 262144 , 242000 are done in 13.157902956008911\n",
      "\t\tOut of 262144 , 243000 are done in 12.95931077003479\n",
      "\t\tOut of 262144 , 244000 are done in 12.691934585571289\n",
      "\t\tOut of 262144 , 245000 are done in 13.068459272384644\n",
      "\t\tOut of 262144 , 246000 are done in 12.615955591201782\n",
      "\t\tOut of 262144 , 247000 are done in 13.256433486938477\n",
      "\t\tOut of 262144 , 248000 are done in 12.763797283172607\n",
      "\t\tOut of 262144 , 249000 are done in 12.891943454742432\n",
      "\t\tOut of 262144 , 250000 are done in 12.668777465820312\n",
      "\t\tOut of 262144 , 251000 are done in 13.31631088256836\n",
      "\t\tOut of 262144 , 252000 are done in 13.288939714431763\n",
      "\t\tOut of 262144 , 253000 are done in 12.907984733581543\n",
      "\t\tOut of 262144 , 254000 are done in 13.240820169448853\n",
      "\t\tOut of 262144 , 255000 are done in 13.115862607955933\n",
      "\t\tOut of 262144 , 256000 are done in 13.410528898239136\n",
      "\t\tOut of 262144 , 257000 are done in 12.957088470458984\n",
      "\t\tOut of 262144 , 258000 are done in 13.338337421417236\n",
      "\t\tOut of 262144 , 259000 are done in 13.306668996810913\n",
      "\t\tOut of 262144 , 260000 are done in 12.899999856948853\n",
      "\t\tOut of 262144 , 261000 are done in 13.185111284255981\n",
      "\t\tOut of 262144 , 262000 are done in 12.910533905029297\n",
      "\tDictionary SAVED for.. 07bca4290a2530091ce1d5f200d9d526\n",
      "Patient.. 5a42f0a0d1e060531c20d04ed23efc02\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'top_voxels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-574f14b99537>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtop_patients_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtop_voxels_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_patients_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mLUNA_model_v2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-c3a8532c5de0>\u001b[0m in \u001b[0;36mtop_voxels_predict\u001b[0;34m(top_patients_DICT, MODEL)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'Patient..'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpatient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mtop_voxels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtop_patients_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpatient\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'top_voxels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_voxels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'top_voxels'"
     ]
    }
   ],
   "source": [
    "\n",
    "top_patients_dict = top_voxels_predict(top_patients_dict,LUNA_model_v2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
