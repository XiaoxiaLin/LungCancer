{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/opt/anaconda/lib/python3.5/site-packages/keras/engine/topology.py:1206: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  return cls(**config)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.48\n",
    "set_session(tf.Session(config=config))\n",
    "\n",
    "from keras.models import load_model\n",
    "PATH_MODEL = \"../Models/LUNA_model_v3_class.h5\"\n",
    "model_class = load_model(PATH_MODEL)\n",
    "\n",
    "PATH_MODEL = \"../Models/LUNA_model_v3_regression.h5\"\n",
    "model_reg = load_model(PATH_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "PATH_VOXELS = '../../data/stage1_voxels_mask/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 1595 labels\n"
     ]
    }
   ],
   "source": [
    "df_labels_1 = pd.read_csv('/home/lin/data/stage1_labels.csv')\n",
    "df_labels_2 = pd.read_csv('/home/lin/data/stage1_solution.csv')\n",
    "df_labels_2 = df_labels_2.drop(['Usage'],1)\n",
    "df_labels = df_labels_1.append(df_labels_2)\n",
    "print (\"Total %d labels\"%df_labels.shape[0])\n",
    "\n",
    "df_labels = df_labels.set_index(df_labels['id'])\n",
    "df_labels.drop(['id'],1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient numbers:  1434\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "patients = [f for f in os.listdir(PATH_VOXELS)]\n",
    "print (\"patient numbers: \", len(patients))\n",
    "\n",
    "noduleDict = {}\n",
    "cancerDistr = []\n",
    "nonCancerDistr = []\n",
    "\n",
    "for num, patient in enumerate(patients):\n",
    "    \n",
    "    if num%100==0:\n",
    "        print (num)\n",
    "    \n",
    "    patient_array = np.load(PATH_VOXELS + patient)\n",
    "    voxels = patient_array['vox']  \n",
    "\n",
    "    preds = np.array(model_class.predict(x= voxels))\n",
    "    \n",
    "    inds = np.array([x for x in range(preds.shape[0])])\n",
    "    \n",
    "    noduleDict[patient[:-4]] = inds[preds[:,1]>0.5]\n",
    "    \n",
    "    if df_labels.loc[patient[:-4]]['cancer']==1:\n",
    "        cancerDistr.extend(list(preds[:,1][preds[:,1]>0.5]))\n",
    "    else:\n",
    "        nonCancerDistr.extend(list(preds[:,1][preds[:,1]>0.5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=[10,7])\n",
    "plt.hist(cancerDistr, label='Cancer patients', alpha=0.5, color='c', normed=True)\n",
    "plt.hist(nonCancerDistr, label='Healthy individuals', alpha=0.5, color='k', normed=True)\n",
    "plt.xlabel('Probability of being a malignant nodule')\n",
    "plt.legend()\n",
    "plt.xlim([0,1])\n",
    "plt.savefig('nodule_prob.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_features = []\n",
    "for num,patient in enumerate(patients):\n",
    "    patient_array = np.load(PATH_VOXELS + patient)\n",
    "\n",
    "    voxels = patient_array['vox'][noduleDict[patient]]\n",
    "    \n",
    "    preds = np.array(model_reg.predict(x= voxels))\n",
    "    ixs = np.argmax(preds[0])\n",
    "    \n",
    "    xmax_malig = np.max(preds[0], axis=0)\n",
    "    xmax_spiculation = np.max(preds[1], axis=0)\n",
    "    xmax_lobulation = np.max(preds[2], axis=0)\n",
    "    xmax_diameter = np.max(preds[3], axis=0)\n",
    "    \n",
    "    xsd_malig = np.std(preds[0], axis=0)\n",
    "    xsd_spiculation = np.std(preds[1], axis=0)\n",
    "    xsd_lobulation = np.std(preds[2], axis=0)\n",
    "    xsd_diameter = np.std(preds[3], axis=0)\n",
    "    \n",
    "    centroids = patient_array['cents']\n",
    "    shape = patient_array['shape']\n",
    "    normalized_locs = centroids.astype('float32') / shape.astype('float32')\n",
    "    \n",
    "    if len(preds)==0:\n",
    "        feats = np.zeros(14)\n",
    "    else:\n",
    "        feats = (np.concatenate([xmax_malig,xmax_spiculation,xmax_lobulation,xmax_diameter,\\\n",
    "               xsd_malig,xsd_spiculation,xsd_lobulation,xsd_diameter,\\\n",
    "               normalized_locs[ixs],normalized_locs.std(axis=0)]))        \n",
    "    print (feats)\n",
    "    \n",
    "    all_features.append(feats)    \n",
    "X = np.stack(all_features)\n",
    "\n",
    "col=['max_malig','max_spiculation','max_lobulation','max_diameter',\\\n",
    "     'xsd_malig', 'xsd_spiculation', 'xmax_lobulation','xsd_diameter','a','a','a','a','a','a']\n",
    "\n",
    "df = pd.DataFrame(data=X, columns=col)\n",
    "df['labels'] = labels\n",
    "\n",
    "df.to_csv('./model3_feature_matrix_kaggle1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
