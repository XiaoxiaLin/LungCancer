{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From Danniel's github\n",
    "\n",
    "\n",
    "https://github.com/dhammack/DSB2017/blob/50ea5d169f6028b907b40276502e744c6b9d12ec/training_code/FLung_nodule_models/score_ident_model_v1.py\n",
    "\n",
    "\n",
    "https://github.com/dhammack/DSB2017/blob/master/scoring_code/score_ident_model_v1_stage2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "from joblib import Parallel, delayed\n",
    "import sys\n",
    "import scipy\n",
    "import cv2\n",
    "import os\n",
    "from os.path import join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_start(arr, thresh=.5):\n",
    "\t#determine when the arr first exceeds thresh\n",
    "\t#arr = arr.ravel()\n",
    "\tfor i in range(arr.shape[0]):\n",
    "\t\tif arr[i] > thresh:\n",
    "\t\t\t#print 'returning', i\n",
    "\t\t\treturn np.clip(i - 8, 0, arr.shape[0])\n",
    "\treturn 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_strides(steps,size,offset,VOXEL_SIZE):\n",
    "\tif steps * VOXEL_SIZE < size - 2*offset:\n",
    "\t\t#not enough coverage. start and end are modified\n",
    "\t\tstart = (size - steps*VOXEL_SIZE) / 2\n",
    "\t\tend = size - start - VOXEL_SIZE\n",
    "\telse:\n",
    "\t\tstart = offset\n",
    "\t\tend = size-VOXEL_SIZE - offset\n",
    "\treturn list(np.around(np.linspace(start,end,steps)).astype('int32'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Danniel's code, the preds are in the original scale (from 0 to 5), and he uses thresh=1.5. That means he is only keeping voxels with malignancy score higher then 1.5. \n",
    "\n",
    "Our CNN is giving normalized malignancy preds (from 0 to 1), if we use   thresh = 1.5/5=0.03, we would end up keeping all (max_ct=50) voxels. This model seems to return very high malignancy score... (?) Does it make sense? Which threshhold is better to apply here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_interesting_ixs(preds,thresh=0.05,max_ct=50):\n",
    "\t#return the indices of interest\n",
    "\tixs = []\n",
    "\t# preds_at_ixs = []\n",
    "\tfor i in range(preds.shape[0]):\n",
    "\t\tif preds[i] > thresh:\n",
    "\t\t\tixs.append(i)\n",
    "\t\t\t# preds_at_ixs.append(preds[i])\n",
    "\t\t\t\n",
    "\tif len(ixs) == 0:\n",
    "\t\tixs = [np.argmax(preds)]\n",
    "\t\t# preds_at_ixs = [preds[np.argmax(preds)]]\n",
    "\t\t\n",
    "\tif len(ixs) > max_ct:\n",
    "\t\tixs = np.argsort(preds)[-max_ct:]\n",
    "\t\t\n",
    "\treturn np.array(ixs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def img_to_vox(img,VOXEL_SIZE,mask):\n",
    "\n",
    "\t#mask == 0 -> inside lung.\n",
    "\t#mask == 1 -> outside lung \n",
    "\t\n",
    "\t#first let's just get the minimum amount of coverage\n",
    "\tsamples0 = int(img.shape[0] / float(VOXEL_SIZE)) + 4\n",
    "\tsamples1 = int(img.shape[1] / float(VOXEL_SIZE)) + 4\n",
    "\tsamples2 = int(img.shape[2] / float(VOXEL_SIZE)) + 4\n",
    "\t\n",
    "\tixs0 = get_strides(samples0,img.shape[0],0,VOXEL_SIZE)\n",
    "\tixs1 = get_strides(samples1,img.shape[1],0,VOXEL_SIZE)\n",
    "\tixs2 = get_strides(samples2,img.shape[2],0,VOXEL_SIZE)\n",
    "\n",
    "\tsubvoxels = []\n",
    "\tlocations = []\n",
    "\tcentroids = []\n",
    "\tfor i0,x0 in enumerate(ixs0):\n",
    "\t\tfor i1,x1 in enumerate(ixs1):\n",
    "\t\t\tfor i2,x2 in enumerate(ixs2):\n",
    "\t\t\t\tif mask[x0:x0+VOXEL_SIZE,x1:x1+VOXEL_SIZE,x2:x2+VOXEL_SIZE].mean() > .99:\n",
    "\t\t\t\t\t#basically no lung in this voxel, might as well ignore.\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\t\tsubvoxels.append(img[x0:x0+VOXEL_SIZE,x1:x1+VOXEL_SIZE,x2:x2+VOXEL_SIZE])\n",
    "\t\t\t\tassert subvoxels[-1].shape == (VOXEL_SIZE,VOXEL_SIZE,VOXEL_SIZE), 'bad subvoxel shape ' + str(subvoxels[-1].shape) + ' ' + str([x0,x1,x2]) + ' ' + str(img.shape)\n",
    "\t\t\t\tlocations.append((i0,i1,i2))\n",
    "\t\t\t\tcentroids.append((x0+VOXEL_SIZE/2,x1+VOXEL_SIZE/2,x2+VOXEL_SIZE/2))\n",
    "\tX = np.stack(subvoxels, axis=0)\n",
    "\t#print 'num subvoxels:', X.shape[0]\n",
    "\tX = np.expand_dims(X, 1)\n",
    "\t#normalized locations\n",
    "\t#allows us to de-weight certain places...\n",
    "\t\n",
    "\treturn X,locations,centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def crop_img(img_cpy):\n",
    "\t# img_raw = np.load(patient)\n",
    "\t# downsample = 1\n",
    "\tmasks = []\n",
    "\timg_raw = img_cpy.copy()\n",
    "\t\n",
    "\tfor i in range(img_raw.shape[2]):\n",
    "\t\timg_slice = img_raw[ :,:,i]\n",
    "\t\timg = img_slice.copy()\n",
    "\n",
    "\t\timg[img>-300] = 255\n",
    "\t\timg[img<-300] = 0\n",
    "\t\timg = np.uint8(img)\n",
    "\t\t_, contours, _ = cv2.findContours(img,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\t\tif len(contours) > 0:\n",
    "\t\t\n",
    "\n",
    "\t\t\tlargest_contour = max(contours, key=cv2.contourArea)\n",
    "\t\telse:\n",
    "\t\t\tmask = (np.zeros(img.shape, np.uint8) < 255)\n",
    "\t\t\tmasks.append(mask)\n",
    "\t\t\tcontinue\n",
    "\t\tmask = np.zeros(img.shape, np.uint8)\n",
    "\t\tcv2.fillPoly(mask, [largest_contour], 255)\n",
    "\n",
    "#\t\t imshow(mask); show()\n",
    "\n",
    "\t\t# apply mask to threshold image to remove outside. this is our new mask\n",
    "\t\timg = ~img \n",
    "\t\timg[(mask == 0)] = 0 # <-- Larger than threshold value\n",
    "\n",
    "\t\t# apply closing to the mask\n",
    "\t\tkernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(5,5))\n",
    "\t\timg = cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)  # <- to remove speckles...\n",
    "\t\timg = cv2.morphologyEx(img, cv2.MORPH_DILATE, kernel)\n",
    "\t\timg = cv2.morphologyEx(img, cv2.MORPH_DILATE, kernel)\n",
    "\t\timg = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
    "\t\timg = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
    "\t\timg = cv2.morphologyEx(img, cv2.MORPH_ERODE, kernel)\n",
    "\t\timg = cv2.morphologyEx(img, cv2.MORPH_ERODE, kernel)\n",
    "\n",
    "\t\t#the image has an outside part which we don't care about (value 0)\n",
    "\t\t#and a boundary that we don't care about (value 255)\n",
    "\t\t#and some noise that we don't care about (value 125)\n",
    "\t\tmask = (img < 255)\n",
    "#\t\t img_raw[~mask] = -2000\n",
    "#\t\t imshow(img_raw); colorbar(); show()\n",
    "\t\tmasks.append(mask)\n",
    "\t\n",
    "\t#now we have one mask per slice. To determine our bounding box, take the max x,y,z plus a fuzz factor\n",
    "\tixs_to_remove = [i for i,m in enumerate(masks) if np.mean(m) > .995]\n",
    "\t\n",
    "\t# masks =[m for m in masks if np.mean(m) < .995]\n",
    "\tmasks = np.stack(masks, axis=2)\n",
    "\tmasks = np.delete(masks, ixs_to_remove, axis=2)\n",
    "\timg_raw = np.delete(img_raw, ixs_to_remove, axis=2)\n",
    "\t\n",
    "\t\n",
    "\t#0 = mask, 1 = background\n",
    "\tx_dim = np.min(masks, axis=(1,2))\n",
    "\ty_dim = np.min(masks, axis=(0,2))\n",
    "\tz_dim = np.min(masks, axis=(0,1))\n",
    "\t\n",
    "\txstart = find_start(1 - x_dim, .5)\n",
    "\txend = -(find_start(1 - x_dim[::-1], .5) + 1)\n",
    "\t\n",
    "\tystart = find_start(1 - y_dim, .5)\n",
    "\tyend = -(find_start(1 - y_dim[::-1], .5) + 1)\n",
    "\t\n",
    "\t\n",
    "\tzstart = find_start(1 - z_dim, .5)\n",
    "\tzend = -( find_start(1 - z_dim[::-1], .5) + 1)\n",
    "\t\n",
    "\t# try:\n",
    "\tassert xstart < int(img_raw.shape[0]*.5) < img_raw.shape[0] - xend, 'bad crop ' + str(xstart) + ' ' + str(xend) + ' ' + str(img_raw.shape[0])\n",
    "\tassert ystart < int(img_raw.shape[1]*.5) < img_raw.shape[1] - yend, 'bad crop ' + str(ystart) + ' ' + str(yend) + ' ' + str(img_raw.shape[1])\n",
    "\tassert zstart < int(img_raw.shape[2]*.5) < img_raw.shape[2] - zend, 'bad crop ' + str(zstart) + ' ' + str(zend) + ' ' + str(img_raw.shape[2])\n",
    "\tassert xend < 0 and yend < 0 and zend < 0, 'one end >= 0'\n",
    "\tassert xstart >= 0 and ystart >= 0 and zstart >= 0, 'one start <= 0'\n",
    "\t# except AssertionError as e:\n",
    "\t\t# print 'WARNING cropping failed. using full img', e\n",
    "\t\t# return img_raw\n",
    "\t\t\n",
    "\treturn img_raw[xstart:xend,ystart:yend,zstart:zend], masks[xstart:xend,ystart:yend,zstart:zend]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_and_txform_file(file,model,VOXEL_SIZE,batch_size,n_TTA=32):\n",
    "\t#read, convert to voxels.\n",
    "\txorig = np.load(os.path.join(\"../../data/stage1_arrays/\", file))\n",
    "\tx = np.clip(xorig.copy(), -1000, 400)\n",
    "\tx,mask = crop_img(x)\n",
    "\n",
    "\tx = ((x + 1000.) / (400. + 1000.)).astype('float32')\n",
    "\tvoxels, locs, centroids = img_to_vox(x,VOXEL_SIZE,mask)\n",
    "\t#predict on voxels, keep top N ROI\n",
    "\tpreds = model.predict(voxels, batch_size=batch_size).ravel()\n",
    "\t\n",
    "\ttopNixs = get_interesting_ixs(preds)\n",
    "\ttopNvox = voxels[topNixs]\n",
    "\ttopNcentroids = np.array(centroids)[topNixs]\n",
    "\ttopNpreds = preds[topNixs]\n",
    "\t\n",
    "\treturn topNvox, topNcentroids, [x.shape] * topNcentroids.shape[0], topNpreds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main \n",
    "\n",
    "At this moment, the model is giving a bad prediction. The malignancy score for all the voxels are quite high. the mean all the top 50 are around 70% FOR ALL VOXELS. (???)\n",
    "\n",
    "I killed the process after 300 patients. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient numbers:  1434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python3.5/site-packages/keras/engine/topology.py:1206: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  return cls(**config)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 patients saved\n",
      "100 patients saved\n",
      "200 patients saved\n",
      "300 patients saved\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-2ff83f76a7a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"%d patients saved\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mvox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_and_txform_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_v24\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVOXEL_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_TTA\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH_VOXELS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'vox_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpatient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH_VOXELS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cents_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpatient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-64082567c4ca>\u001b[0m in \u001b[0;36mload_and_txform_file\u001b[0;34m(file, model, VOXEL_SIZE, batch_size, n_TTA)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mvoxels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcentroids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_to_vox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mVOXEL_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m#predict on voxels, keep top N ROI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvoxels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mtopNixs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_interesting_ixs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1570\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1571\u001b[0m         return self._predict_loop(f, ins,\n\u001b[0;32m-> 1572\u001b[0;31m                                   batch_size=batch_size, verbose=verbose)\n\u001b[0m\u001b[1;32m   1573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1574\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_predict_loop\u001b[0;34m(self, f, ins, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1200\u001b[0m                 \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1202\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1203\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1204\u001b[0m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2071\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2072\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2073\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2074\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2075\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lin/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lin/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lin/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/lin/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lin/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "PATH_RAW_ARRAY = \"../../data/stage1_arrays/\"\n",
    "PATH_VOXELS = \"../../data/stage1_TOP_voxels/\"\n",
    "PATH_MODEL = \"../../../katya/LungCancer/Katya/CNN_v2/model_and_weights/model_LUNA_v2_24.h5\"\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    patients = [f for f in os.listdir(PATH_RAW_ARRAY) if '.npy' in f]\n",
    "    print (\"patient numbers: \", len(patients) )\n",
    "    model_v24 = load_model(PATH_MODEL)\n",
    "    VOXEL_SIZE = 64\n",
    "    \n",
    "    for num, patient in enumerate(patients):\n",
    "        if num >300:\n",
    "            if num%100 == 0:\n",
    "                print (\"%d patients saved\"%num)\n",
    "            vox, cents, shapes, preds = load_and_txform_file(patient, model_v24, VOXEL_SIZE, batch_size=32, n_TTA=2)\n",
    "            np.save(join(PATH_VOXELS, 'vox_' + patient), vox)\n",
    "            np.save(join(PATH_VOXELS, 'cents_' + patient), cents)\n",
    "            np.save(join(PATH_VOXELS, 'shapes_' + patient), shapes)\n",
    "            np.save(join(PATH_VOXELS, 'preds_' + patient), preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "patient:  f8f66fca04d2e67eacd86ea154827a4c.npy\n",
      "original shape: (394, 394, 306)\n",
      "croped img shape: (358, 271, 240)\n",
      "malignancy range:  0.0618467 0.79049\n",
      "\n",
      "patient:  1278988821a696e534c6c93ecdd4ff0c.npy\n",
      "original shape: (264, 264, 304)\n",
      "croped img shape: (253, 191, 284)\n",
      "malignancy range:  0.0607603 0.774071\n",
      "\n",
      "patient:  57af0020213d64598ede82fe9d6bb8b3.npy\n",
      "original shape: (360, 360, 295)\n",
      "croped img shape: (317, 303, 252)\n",
      "malignancy range:  0.0677545 0.759359\n",
      "\n",
      "patient:  e4436b5914162ff7efea2bdfb71c19ae.npy\n",
      "original shape: (348, 348, 332)\n",
      "croped img shape: (308, 205, 295)\n",
      "malignancy range:  0.0705277 0.749056\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,5):\n",
    "    xorig = np.load(os.path.join(\"../../data/stage1_arrays/\", patients[i]))\n",
    "    print (\"\\npatient: \", patients[i])\n",
    "    print (\"original shape:\", xorig.shape)\n",
    "    x = np.clip(xorig.copy(), -1000, 400)\n",
    "\n",
    "    x,mask = crop_img(x)\n",
    "    x = ((x + 1000.) / (400. + 1000.)).astype('float32')\n",
    "    print (\"croped img shape:\",x.shape)\n",
    "    voxels, locs, centroids = img_to_vox(x,VOXEL_SIZE,mask)\n",
    "    preds = model_v24.predict(voxels, batch_size=20).ravel()\n",
    "    print (\"malignancy range: \", np.min(preds), np.max(preds)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0549898 0.961901\n"
     ]
    }
   ],
   "source": [
    "print (np.min(preds), np.max(preds)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
